{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Text Generator\n",
    "\n",
    "Write a bare-bones Markov text generator.\n",
    "Implement a function of the form\n",
    "finish_sentence(sentence, n, corpus, deterministic=False)\n",
    "that takes four arguments:\n",
    "1. a sentence [list of tokens] that weâ€™re trying to build on,\n",
    "2. n [int], the length of n-grams to use for prediction, and\n",
    "3. a source corpus [list of tokens]\n",
    "4. a flag indicating whether the process should be deterministic [bool]\n",
    "and returns an extended sentence until the first ., ?, or ! is found OR until it has 10 total\n",
    "tokens.\n",
    "\n",
    "\n",
    "If the input flag deterministic is true, choose at each step the single most probable next\n",
    "token. When two tokens are equally probable, choose the one that occurs first in the corpus.\n",
    "\n",
    "If deterministic is false, draw the next word randomly from the appropriate distribution.\n",
    "Use stupid backoff and no smoothing.\n",
    "\n",
    "Provide some example applications of your function in both deterministic and\n",
    "stochastic modes, for a few sets of seed words and a few different n.\n",
    "\n",
    "## Package using \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "### 1. Backoff function\n",
    "In a backoff n-gram model, if the n-gram we need has zero counts, we approximate it by backing off to the (N-1)-gram. We continue backing off until we reach a history that has some counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backoff(last_n_words, n, corpus):\n",
    "    try:\n",
    "        words = np.array([])\n",
    "        freqs = np.array([])\n",
    "        for i in range(len(corpus)-n): \n",
    "            if corpus[i:i+n-1] == last_n_words: \n",
    "                if np.isin(corpus[i+n-1], words) == False: \n",
    "                    words = np.append(words, corpus[i+n-1]) \n",
    "                    freqs = np.append(freqs, 1) \n",
    "                else:\n",
    "                    freqs[words == corpus[i+n-1]] += 1 \n",
    "        return words,freqs\n",
    "    except:\n",
    "        last_n_words_in_corpus = backoff(last_n_words, n-1, corpus) # If n-grams are not found, backoff to n-1-grams\n",
    "    return last_n_words_in_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finish a sentence with n-grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_sentence(tokens, n, corpus, deterministic): \n",
    "    \n",
    "    for i in range(10):\n",
    "        last_n_words = tokens[-(n-1):] \n",
    "        last_n_words_in_corpus, freqs = backoff(last_n_words, n, corpus) \n",
    "        if deterministic:\n",
    "            next_words = last_n_words_in_corpus[np.argmax(freqs)] \n",
    "        else:\n",
    "            next_words = random.choice(last_n_words_in_corpus) \n",
    "        tokens.append(next_words)\n",
    "        if next_words in ['.', '!', '?']:\n",
    "            break\n",
    "        elif len(tokens) == 10: \n",
    "            break\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test\n",
    "Firstly, we set our corpus for the Markov function as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = nltk.word_tokenize(\n",
    "        nltk.corpus.gutenberg.raw(\"austen-sense.txt\").lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 1\n",
    "\n",
    "In the first test case here we set the \n",
    "\n",
    "        tokens = [\"she\", \"was\", \"not\"]\n",
    "        n  =  3\n",
    "        deterministic = True\n",
    "\n",
    "We get the result as our expected as following:\n",
    "\n",
    "        ['she', 'was', 'not', 'in', 'the', 'world', '.']\n",
    "\n",
    "#### Case 2\n",
    "Let's try to change the \n",
    "        \n",
    "        deterministic = False\n",
    "In this case, the deterministic = False, we randomly pick the words. \n",
    "and we get the following results:\n",
    "\n",
    "        First run: ['she', 'was', 'not', 'it', 'what', 'you', 'tell', 'me', 'that', 'it']\n",
    "        Second run: ['she', 'was', 'not', 'beyond', 'one', 'day', 'that', 'she', 'wishes', 'for']\n",
    "\n",
    "#### Case 3\n",
    "Then we change the\n",
    "        \n",
    "         n = 4. \n",
    "In this case, we set our the length of n-grams to 4 using for the prediction.\n",
    "we get the following results:\n",
    "\n",
    "        ['she', 'was', 'not', 'in', 'the', 'habit', 'of', 'seeing', 'much', 'occupation']\n",
    "\n",
    "#### Case 4\n",
    "We change our token seed as \n",
    "\n",
    "        ['she', \"was\", \"not\", \"that\"]\n",
    "and we get the following:\n",
    "\n",
    "        ['she', 'was', 'not', 'that', 'i', 'have', 'been', 'so', 'happy', ',']\n",
    "\n",
    "#### Case 5\n",
    "We change the token seed and n as :\n",
    "\n",
    "       Token = ['she', \"was\", \"not\", \"that\"] \n",
    "        n = 2\n",
    "we get the following result:\n",
    "\n",
    "        ['she', 'was', 'not', 'that', 'she', 'was', 'not', 'be', 'a', 'very']\n",
    "\n",
    "#### Case 6\n",
    "We change the token seed, n, and the deterministic as :\n",
    "\n",
    "       Token = ['she', \"was\", \"not\", \"that\"] \n",
    "        n = 2\n",
    "        deterministic = False\n",
    "\n",
    "We get the following:\n",
    "\n",
    "        ['she', 'was', 'not', 'that', 'all', 'cousins', 'the', 'girls', ';', 'prepared']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac6dcd399ab8cd2ecc0f6e8f154efd75b4aa37c8093b73598011b1aae01f02fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
